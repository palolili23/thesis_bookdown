# Discussion

## Main findings / Principal findings

The aim in Chapter 2 was to emulate a hypothethical randomized trial - a target trial - for estimating observational analogues to intention-to-treat and per-protocol effects of statins in the risk of dementia. In this study we found that individuals with sustained statin use, but not statin initiation alone had reduced 10-year risks of dementia and dementia or death. 
To anwer this question we preventing one of the most important bias in pharmaco-epidemiology studies, the prevalent user bias. To overcome this situation, a clear definition of the eligibility criteria which includes participants with no statin prescription in the previous two years, and no previous diagnosis of dementia prevents potential reverse causation. Given that only few participants would be included in the treatment arm, this study is the first one to apply the methodology of "sequence of trials". This means that, rather than conceptualizing on point in time as the time zero, eligibility criteria is assessed every month between February 1993 and December 2007. That represented 180 trials, each of them with a 1-month enrollment period. As described in Chapter 2, baseline variables are updated at the start of each trial. Data is pooled from all 180 trials into a single model. 
This allows us to go from 6373 eligible participants in the study, to 1578655 potential person trials.

Though results should be interpreted with caution, due to the yet small number of initiators and events, and potential residual confunding. This design brings an opportunity to increase sample size in respect to new users, one of the concerns when considering a new-user design target trial. However, since the publication of this study, new studies have continuously per
It is unfortunate that more recent work, such as Zhou 2021, contrasts current-users vs. non-users at baseline, when the had over 1700 new users in this trial.

This issue, the gap between the theory developed in epidemiologic methods and applications is should be more of a concern for the field....


The same gap is found in the research specifically focused in understanding the effect of hypertension, or better yet, the effect of reducing blood pressure under clinical thresholds in the risk of dementia. In one hand, we have randomized controlled trials that looked at the effect of specific antihypertensives, or alternatively, the effect of keeping blood pressure under clinical thresholds, such as the iconic SPRINT-Mind trial. In the other hand, we have observational studies that are either looking at the effect of antihypertensives with the design issues we described above (such as the prevalent user desing), or look at systolic blood pressure, categorizing participants under different cutt-offs, mostly specified at baseline or over follow-up. (Maybe say something about Ding).
We attempt to bridge these two sides of research in Chapter 3. The aim of this study was to emulate a target trial to estimate the sustained effect of several hypothetical interventions on systolic blood pressure control, including in combination with an intervention on smoking over follow-up, on the risk of first-ever stroke and dementia using data from 15 years of follow-up in the Rotterdam Study.

All interventions that involved reducing SBP were associated with a stroke risk reduction of about 10%, and joint interventions on SBP and smoking status further decreased the risk of stroke in over 15% (e.g. reducing SBP by 20% if above 140mmHg and quit smoking risk ratio: 0.83; 95% CI 0.71 - 0.94). In contrast, we did not observe a change in the risk of dementia. 

**About competing events.**

Competing events is probably the most exciting methodologic problem I faced in my career. Specially because it is often taught as an advanced method in survival analysis and not frequently used or well understood. But, as opposed to the believe that research questions with competing events are the exception, I believe that they happen very frequently. The field of dementia and other aging-related diseases is specially affected to competing events, given that participants may die from other conditions before developing dementia.

In Chapter 5 I reviewed over fifty papers published in top journals. Our aim was to understand what are the current practices and.
Although about 80% of papers had follow-up longer than 5 years, almost half of the papers did not even mention how many participants had died over follow-up, and only few had described the number of deaths on each exposure group. In some cases, death was not even mention when the lenght of follow-up for each participant was described.

My take aways

The idea that when competing events are present, there is more than one "risk" estimand, is very old. In fact, prior to the development of Cox-regression models, in the 70's Tsiatsis had already outline at least two types of risks: the "net risk" and the "crude risk". The net risk was defined as the risk of the main outcome in settings where the competing event could have been eliminated. As opposed, the crude risk represented the risk of the main outcome when the competing event is also present. This lead to many discussions in that time already, and there was a big emphasis on the problems of relying on the independent censoring assumption when it is not verifiable in the observed data. But they raised one key point that is often forgotten, relying on this assumption requires deep knowledge on the biological process and expertise knowledge on the topic.

Many researchers question what is the clinical meaning or the usefulness of question where the competing event could have been prevented/eliminatated. For example Thernau, author of the R "survival" package, formulated that "_in this hypothetical world it is indeed true that many more subjects would progress to PMC, but it is also not a world that any of us will ever inhabit. This author views the result in much the same light as discussions of survival after the zombie apocalypse_". Likewise Andersen et al. adviced strongly to "stick to this world" in their paper on xx.

These cautionary recommendations make sense, up to the point that some may ask, why did we ever consider this as a useful estimand? To understand this, it is key to go back to the origins of the study of competing events, which goes back to the 18th century. Back in those days, there was a smallpox pandemic, and as such, several attempts to develop treatments where under study. One of them was innoculation of smallpox. In different countries, several physicians tested if smallpox innoculation could prevent the disease, though in extremely unethical and violent circumstances (such as testing in slave's children). 
Bernoulli created life tables to count how many people died from smallpox and from other causes of disease and described a counterfactual scenario where death due to smallpox could have been eliminated. His underlying question was, how many deaths could be prevented with inoculation? 
This counterfactual scenario makes sense for smallpox and any other infectious disease, currently the WHO is still trying to erradicate infectious disease that are present in low-middle income countries and low income countries, so imagining a world where death from ID are prevented, looks more like looking at the WHO charts from high income countries than considering survival after a zombie apocalipse. In fact, in the current state of the world, we could even ask what would be the risk of dementia if we could have prevented all deaths caused by Covid-19?

At that time, Bernoulli's theory and calculations caused some negative reactions by others, such as D'Alembert. He believed that mathematics and probability should be applied to real-world scenarios, and labeled Bernoulli's assumptions as the "_art of conjecture_", where _conjecture_ means . I was fascinated with this story, because I feel that the most trascending debates in causal inference are related to the assumptions - or conjectures - we dare to believe or imagine, where in reality _data_ is not necessary equivalent to _information_.

The debate on what estimands we have available has lost attention, as the attention turned to the 





## General synthesis

### Broader implications

### Future directions

#### Applied dementia research

#### Methods develompment

#### Software and educational resources

## Conclusion




Methodological considerations

 * Identifiability challenges
 
- Unmeasured confounding: For the statins paper is confounding by indication. For systolic blood pressure, comorbidities, frailty, hypertension medication. For pin1 it's just crazy

- Unmeasured confounding related to the controlled direct effect in competing events

- Consistency: 

- The tabu behind the well-defined intervention. Talk a bit about does water kill and maybe some prior concepts about consistency. In statins we assume that the effect of statins is consistent across statin types, and historically too.
In the case of blood pressure, although we mimiqued the sprint trial, we are not clear about how... problems with defining.
Mention that it is very hard to define time zero in settings of biomarkers, worse when a disease diagnosis is considered the exposure. Sometimes yes, a measurement of a biomarker may lead to an action, but in settings where the biomarker is measured in a different setting, this becomes more challenging.


Consistency has to do also with how we frame our questions, is it the ITT effect or the sustained effect?
To do this, the common challenge observed in statins and in cancer is defining the time zero
.

In statins we used a sophisticated method, but which's replicability and flexibility is not yet accessible. for example, we only addressed the cde and the combined outcome.
For the cancer, since you can only transition from one arm to the other, there is no clear time-window at best we fit IPW up to x.

Positivity. The RS included participants from x to y age and followed them throught time. Ideally, in a target trial setting we would have selected younger participants. If restrict to the first cohort, and with 

- combining sources o

Future directions

- Social determinants of health

- there are many related to dementia. a frequent one is education

- Alternative estimands for incident outcomes and competing events

* Separable effects

* Life-expectancy issues


By representing each step that goes from the imaginary hypothesis to the data-generation mechanisns, through causal diagrams, we were able to dissect several sources of bias, some of which we can prevent by design or within the analysis, but some leave room to bigger discussions in respect to how to continue 

Epilogue
